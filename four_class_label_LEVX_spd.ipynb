{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "four_class_label_LEVX_spd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/granantuin/LEVX_class/blob/master/four_class_label_LEVX_spd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLs1xBeqNp1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix,accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,cross_validate,GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyvF9dvOUVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aegaoIOOO03B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(y_test,y_pred):\n",
        "  index=[\"less than 2 m/s\",\"medium\",\"more than 10 m/s\"]\n",
        "  print(pd.DataFrame(confusion_matrix(y_test, y_pred), index=index, columns=index))\n",
        "  print(\"****************\")\n",
        "  print(\"Accuracy=\",\"{:.2%}\".format(accuracy_score(y_test, y_pred)),\"// Model Accuracy=45%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average=None, )\n",
        "  df=pd.DataFrame({\"Precision\":results[0],\"Recall\":results[1],\"F1\":results[2],\"W_SPD\":index})\n",
        "  df=df.set_index(\"W_SPD\")\n",
        "  print(\"Average precision =\",\"{:.2%}\".format(df[\"Precision\"].mean()),\"// Model precision=28%\")\n",
        "  print(\"Average recall =\",\"{:.2%}\".format(df[\"Recall\"].mean()),\"// Model recall=28%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average='weighted', )\n",
        "  print(\"Precision weighted=\",\"{:.2%}\".format(results[0]),\"//Model weighted=56%\")\n",
        "  print(\"Recall weighted =\",\"{:.2%}\".format(results[1]),\"//Model weighted=53%\")\n",
        "  print(\"****************\")\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrRN8IcPIVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_4km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_4km_h24toh48_dir/\"\n",
        "drive_1km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_Mars_H24to48_dir/\"\n",
        "drive_metar=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Metar_2018/\"\n",
        "dr=[drive_4km,drive_1km,drive_metar]\n",
        "y_data=pd.read_excel(dr[2]+\"y_LEVX_spd.xlsx\",index_col=0)\n",
        "x_data=pd.read_csv(dr[2]+\"x_LEVX.csv\",index_col=0)\n",
        "x_data=x_data.iloc[:,0:9]\n",
        "y_data=y_data[y_data>0]# delete station errors\n",
        "result = x_data.join(y_data, how='outer').dropna()\n",
        "x_data=result.iloc[:,0:9]\n",
        "y_data=result.iloc[:,9:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsrNL1CdQMKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L=y_data[y_data[\"value\"]<2]\n",
        "L[\"label\"]=\"less than 2 m/s\"\n",
        "M=y_data[(y_data[\"value\"]>=2) & (y_data[\"value\"]<=10)]\n",
        "M[\"label\"]=\"medium\"\n",
        "H=y_data[y_data[\"value\"]>10]\n",
        "H[\"label\"]=\"more than 10 m/s\"\n",
        "spds=[L,M,H]\n",
        "y_data=pd.concat(spds)\n",
        "y_data=y_data.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ChFv8sU99p",
        "colab_type": "text"
      },
      "source": [
        "**Dummy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_0baWzkSPcK",
        "colab_type": "code",
        "outputId": "2d8669fe-3d40-48c0-9d17-510ea20bd8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = DummyClassifier(strategy=\"most_frequent\").fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s                 0     134                 0\n",
            "medium                          0    1770                 0\n",
            "more than 10 m/s                0     544                 0\n",
            "****************\n",
            "Accuracy= 72.30% // Model Accuracy=45%\n",
            "Average precision = 24.10% // Model precision=28%\n",
            "Average recall = 33.33% // Model recall=28%\n",
            "Precision weighted= 52.28% //Model weighted=56%\n",
            "Recall weighted = 72.30% //Model weighted=53%\n",
            "****************\n",
            "                  Precision  Recall       F1\n",
            "W_SPD                                       \n",
            "less than 2 m/s    0.000000     0.0  0.00000\n",
            "medium             0.723039     1.0  0.83926\n",
            "more than 10 m/s   0.000000     0.0  0.00000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP8X98XvVmIO",
        "colab_type": "code",
        "outputId": "f74e58b9-ae88-443a-cbd6-042a964d584b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "clas = [RandomForestClassifier(n_estimators= 200, max_depth= 100, bootstrap= True),\n",
        "       ExtraTreesClassifier(),AdaBoostClassifier(),GaussianNB()]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s                 0     128                 6\n",
            "medium                          0    1587               183\n",
            "more than 10 m/s                0     266               278\n",
            "****************\n",
            "Accuracy= 76.18% // Model Accuracy=45%\n",
            "Average precision = 46.55% // Model precision=28%\n",
            "Average recall = 46.92% // Model recall=28%\n",
            "Precision weighted= 71.15% //Model weighted=56%\n",
            "Recall weighted = 76.18% //Model weighted=53%\n",
            "****************\n",
            "                  Precision    Recall        F1\n",
            "W_SPD                                          \n",
            "less than 2 m/s    0.000000  0.000000  0.000000\n",
            "medium             0.801111  0.896610  0.846174\n",
            "more than 10 m/s   0.595289  0.511029  0.549951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3E-m028XiXq",
        "colab_type": "text"
      },
      "source": [
        "**K_Folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdr3GG16W8na",
        "colab_type": "code",
        "outputId": "b3457c0e-c381-4646-b8c1-6b75ef7efd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 73.83% (+/- 5.39%)\n",
            "Recall: 43.20% (+/- 9.23%)\n",
            "Precision: 45.02% (+/- 8.74%)\n",
            "f1 : 42.56% (+/-9.13% )\n",
            "Recall weighted: 73.83% (+/- 5.39%)\n",
            "Precision weighted: 68.57% (+/- 7.98%)\n",
            "f1 weighted: 69.80% (+/-7.39% )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_NbNCg8rtv",
        "colab_type": "text"
      },
      "source": [
        "**Synthetic samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UIw_KNz8y0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8cf21f51-1640-4440-8911-031d0d1013c7"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.4, random_state=27)\n",
        "print(\"Original train samples=\",x_train.shape[0])\n",
        "sm = SMOTE(random_state=27,)\n",
        "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
        "print(\"Synthetic train samples=\",x_train.shape[0])\n",
        "\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original train samples= 4894\n",
            "Synthetic train samples= 10563\n",
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s                20     138                14\n",
            "medium                        196    1724               387\n",
            "more than 10 m/s               31     261               493\n",
            "****************\n",
            "Accuracy= 68.54% // Model Accuracy=45%\n",
            "Average precision = 48.15% // Model precision=28%\n",
            "Average recall = 49.72% // Model recall=28%\n",
            "Precision weighted= 71.09% //Model weighted=56%\n",
            "Recall weighted = 68.54% //Model weighted=53%\n",
            "****************\n",
            "                  Precision    Recall        F1\n",
            "W_SPD                                          \n",
            "less than 2 m/s    0.080972  0.116279  0.095465\n",
            "medium             0.812058  0.747291  0.778330\n",
            "more than 10 m/s   0.551454  0.628025  0.587254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZTDaS986-e",
        "colab_type": "text"
      },
      "source": [
        "**K_ folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnInjRUf8kA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "415cc350-1a94-4f9b-a585-a4c89112261b"
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 73.65% (+/- 4.91%)\n",
            "Recall: 42.78% (+/- 9.62%)\n",
            "Precision: 44.79% (+/- 8.32%)\n",
            "f1 : 42.01% (+/-9.75% )\n",
            "Recall weighted: 73.65% (+/- 4.91%)\n",
            "Precision weighted: 68.29% (+/- 7.73%)\n",
            "f1 weighted: 69.39% (+/-7.58% )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vqouSCt9NUu",
        "colab_type": "text"
      },
      "source": [
        "**Tuning RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b5FCQt89SC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "bc98f8e4-857e-44ce-ae44-7da4323dde93"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.25,\n",
        "                                                    random_state=27)\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
        "                               n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(x_train, y_train)\n",
        "print(\"best parameters\",rf_random.best_params_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.6min\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 10.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKD3Kqpg_stJ",
        "colab_type": "text"
      },
      "source": [
        "**K folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbVuznYs_rBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "3ad07710-c924-48a0-c5bf-d0be74896b97"
      },
      "source": [
        "clas=RandomForestClassifier(n_estimators= 1000, min_samples_split= 10, min_samples_leaf= 1, max_features= 'sqrt', max_depth= 30, bootstrap= True)\n",
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas, x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 74.32% (+/- 5.81%)\n",
            "Recall: 43.07% (+/- 10.12%)\n",
            "Precision: 45.79% (+/- 9.40%)\n",
            "f1 : 42.42% (+/-10.37% )\n",
            "Recall weighted: 74.32% (+/- 5.81%)\n",
            "Precision weighted: 69.05% (+/- 8.54%)\n",
            "f1 weighted: 69.91% (+/-8.36% )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}