{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "four_class_label_LEVX_spd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/granantuin/LEVX_class/blob/master/four_class_label_LEVX_spd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLs1xBeqNp1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix,accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,cross_validate,GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyvF9dvOUVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aegaoIOOO03B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(y_test,y_pred):\n",
        "  index=[\"less than 2 m/s\",\"medium\",\"more than 10 m/s\"]\n",
        "  print(pd.DataFrame(confusion_matrix(y_test, y_pred), index=index, columns=index))\n",
        "  print(\"****************\")\n",
        "  print(\"Accuracy=\",\"{:.2%}\".format(accuracy_score(y_test, y_pred)),\"// Model Accuracy=45%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average=None, )\n",
        "  df=pd.DataFrame({\"Precision\":results[0],\"Recall\":results[1],\"F1\":results[2],\"W_SPD\":index})\n",
        "  df=df.set_index(\"W_SPD\")\n",
        "  print(\"Average precision =\",\"{:.2%}\".format(df[\"Precision\"].mean()),\"// Model precision=28%\")\n",
        "  print(\"Average recall =\",\"{:.2%}\".format(df[\"Recall\"].mean()),\"// Model recall=28%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average='weighted', )\n",
        "  print(\"Precision weighted=\",\"{:.2%}\".format(results[0]),\"//Model weighted=56%\")\n",
        "  print(\"Recall weighted =\",\"{:.2%}\".format(results[1]),\"//Model weighted=53%\")\n",
        "  print(\"****************\")\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrRN8IcPIVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_4km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_4km_h24toh48_dir/\"\n",
        "drive_1km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_Mars_H24to48_dir/\"\n",
        "drive_metar=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Metar_2018/\"\n",
        "dr=[drive_4km,drive_1km,drive_metar]\n",
        "y_data=pd.read_excel(dr[2]+\"y_LEVX_spd.xlsx\",index_col=0)\n",
        "x_data=pd.read_csv(dr[2]+\"x_LEVX.csv\",index_col=0)\n",
        "x_data=x_data.iloc[:,9:18]\n",
        "y_data=y_data[y_data>0]# delete station errors\n",
        "result = x_data.join(y_data, how='outer').dropna()\n",
        "x_data=result.iloc[:,0:9]\n",
        "y_data=result.iloc[:,9:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsrNL1CdQMKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L=y_data[y_data[\"value\"]<2]\n",
        "L[\"label\"]=\"less than 2 m/s\"\n",
        "M=y_data[(y_data[\"value\"]>=2) & (y_data[\"value\"]<=10)]\n",
        "M[\"label\"]=\"medium\"\n",
        "H=y_data[y_data[\"value\"]>10]\n",
        "H[\"label\"]=\"more than 10 m/s\"\n",
        "spds=[L,M,H]\n",
        "y_data=pd.concat(spds)\n",
        "y_data=y_data.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ChFv8sU99p",
        "colab_type": "text"
      },
      "source": [
        "**Dummy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_0baWzkSPcK",
        "colab_type": "code",
        "outputId": "7d24f5d8-46d3-4d05-c5d1-a38363a1f543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = DummyClassifier(strategy=\"most_frequent\").fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s                 0     680                 0\n",
            "medium                          0    1760                 0\n",
            "more than 10 m/s                0       8                 0\n",
            "****************\n",
            "Accuracy= 71.90% // Model Accuracy=45%\n",
            "Average precision = 23.97% // Model precision=28%\n",
            "Average recall = 33.33% // Model recall=28%\n",
            "Precision weighted= 51.69% //Model weighted=56%\n",
            "Recall weighted = 71.90% //Model weighted=53%\n",
            "****************\n",
            "                  Precision  Recall        F1\n",
            "W_SPD                                        \n",
            "less than 2 m/s    0.000000     0.0  0.000000\n",
            "medium             0.718954     1.0  0.836502\n",
            "more than 10 m/s   0.000000     0.0  0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP8X98XvVmIO",
        "colab_type": "code",
        "outputId": "fcd2c290-ac52-4f47-9d76-1fd742ba2549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "clas = [RandomForestClassifier(n_estimators= 200, max_depth= 100, bootstrap= True),\n",
        "       ExtraTreesClassifier(),AdaBoostClassifier(),GaussianNB()]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s               245     435                 0\n",
            "medium                        190    1568                 2\n",
            "more than 10 m/s                0       7                 1\n",
            "****************\n",
            "Accuracy= 74.10% // Model Accuracy=45%\n",
            "Average precision = 55.89% // Model precision=28%\n",
            "Average recall = 45.87% // Model recall=28%\n",
            "Precision weighted= 71.84% //Model weighted=56%\n",
            "Recall weighted = 74.10% //Model weighted=53%\n",
            "****************\n",
            "                  Precision    Recall        F1\n",
            "W_SPD                                          \n",
            "less than 2 m/s    0.563218  0.360294  0.439462\n",
            "medium             0.780100  0.890909  0.831830\n",
            "more than 10 m/s   0.333333  0.125000  0.181818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3E-m028XiXq",
        "colab_type": "text"
      },
      "source": [
        "**K_Folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdr3GG16W8na",
        "colab_type": "code",
        "outputId": "472b6f65-ee53-4b60-f1a2-cf603aaa1e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 72.91% (+/- 2.98%)\n",
            "Recall: 46.36% (+/- 11.38%)\n",
            "Precision: 59.83% (+/- 31.71%)\n",
            "f1 : 47.58% (+/-11.44% )\n",
            "Recall weighted: 72.91% (+/- 2.98%)\n",
            "Precision weighted: 71.11% (+/- 2.78%)\n",
            "f1 weighted: 71.00% (+/-3.03% )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_NbNCg8rtv",
        "colab_type": "text"
      },
      "source": [
        "**Synthetic samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UIw_KNz8y0O",
        "colab_type": "code",
        "outputId": "847f84b4-8fd2-4dd9-86b6-c1a29e731319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.4, random_state=27)\n",
        "print(\"Original train samples=\",x_train.shape[0])\n",
        "sm = SMOTE(random_state=27,)\n",
        "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
        "print(\"Synthetic train samples=\",x_train.shape[0])\n",
        "\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original train samples= 4894\n",
            "Synthetic train samples= 10509\n",
            "                  less than 2 m/s  medium  more than 10 m/s\n",
            "less than 2 m/s               523     359                 0\n",
            "medium                        508    1796                64\n",
            "more than 10 m/s                0       6                 8\n",
            "****************\n",
            "Accuracy= 71.29% // Model Accuracy=45%\n",
            "Average precision = 48.32% // Model precision=28%\n",
            "Average recall = 64.09% // Model recall=28%\n",
            "Precision weighted= 74.05% //Model weighted=56%\n",
            "Recall weighted = 71.29% //Model weighted=53%\n",
            "****************\n",
            "                  Precision    Recall        F1\n",
            "W_SPD                                          \n",
            "less than 2 m/s    0.507274  0.592971  0.546785\n",
            "medium             0.831097  0.758446  0.793111\n",
            "more than 10 m/s   0.111111  0.571429  0.186047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZTDaS986-e",
        "colab_type": "text"
      },
      "source": [
        "**K_ folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnInjRUf8kA4",
        "colab_type": "code",
        "outputId": "9631c099-942d-40bd-b3d2-bbb634a784f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 72.60% (+/- 3.46%)\n",
            "Recall: 46.06% (+/- 11.30%)\n",
            "Precision: 59.31% (+/- 31.79%)\n",
            "f1 : 47.04% (+/-11.09% )\n",
            "Recall weighted: 72.60% (+/- 3.46%)\n",
            "Precision weighted: 70.79% (+/- 3.00%)\n",
            "f1 weighted: 70.60% (+/-3.40% )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vqouSCt9NUu",
        "colab_type": "text"
      },
      "source": [
        "**Tuning RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b5FCQt89SC7",
        "colab_type": "code",
        "outputId": "fd06fc57-1f43-4aa0-f2f8-ed3bfae31fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.25,\n",
        "                                                    random_state=27)\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
        "                               n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(x_train, y_train)\n",
        "print(\"best parameters\",rf_random.best_params_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.6min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 10.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKD3Kqpg_stJ",
        "colab_type": "text"
      },
      "source": [
        "**K folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbVuznYs_rBB",
        "colab_type": "code",
        "outputId": "4e93e06b-487d-4e6c-874e-593945b2efbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "clas=RandomForestClassifier(n_estimators= 200, min_samples_split= 5, min_samples_leaf= 2, max_features= 'sqrt', max_depth= 10, bootstrap= True)\n",
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas, x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 73.73% (+/- 1.95%)\n",
            "Recall: 46.56% (+/- 11.12%)\n",
            "Precision: 60.27% (+/- 31.52%)\n",
            "f1 : 47.50% (+/-10.29% )\n",
            "Recall weighted: 73.73% (+/- 1.95%)\n",
            "Precision weighted: 71.88% (+/- 2.48%)\n",
            "f1 weighted: 71.49% (+/-2.99% )\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}