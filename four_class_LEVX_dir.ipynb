{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "four_class_LEVX_dir.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/granantuin/LEVX_class/blob/master/four_class_LEVX_dir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2yjZo0iz3Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix,accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,cross_validate,GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G2SFv5B0XBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvkfiKL3nOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(y_test,y_pred):\n",
        "  index=[\"E\",\"N\",\"NE\",\"NW\",\"S\",\"SE\",\"SW\",\"W\"]\n",
        "  print(pd.DataFrame(confusion_matrix(y_test, y_pred), index=index, columns=index))\n",
        "  print(\"****************\")\n",
        "  print(\"Accuracy=\",\"{:.2%}\".format(accuracy_score(y_test, y_pred)),\"// Model Accuracy=45%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average=None, )\n",
        "  df=pd.DataFrame({\"Precision\":results[0],\"Recall\":results[1],\"F1\":results[2],\"W_DIR\":index})\n",
        "  df=df.set_index(\"W_DIR\")\n",
        "  print(\"Average precision =\",\"{:.2%}\".format(df[\"Precision\"].mean()),\"// Model precision=28%\")\n",
        "  print(\"Average recall =\",\"{:.2%}\".format(df[\"Recall\"].mean()),\"// Model recall=28%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average='weighted', )\n",
        "  print(\"Precision weighted=\",\"{:.2%}\".format(results[0]),\"//Model weighted=56%\")\n",
        "  print(\"Recall weighted =\",\"{:.2%}\".format(results[1]),\"//Model weighted=53%\")\n",
        "  print(\"****************\")\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHfznTP1-Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_4km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_4km_h24toh48_dir/\"\n",
        "drive_1km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_Mars_H24to48_dir/\"\n",
        "drive_metar=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Metar_2018/\"\n",
        "dr=[drive_4km,drive_1km,drive_metar]\n",
        "y_data=pd.read_excel(dr[2]+\"y_LEVX_dir.xlsx\",index_col=0)\n",
        "x_data=pd.read_csv(dr[2]+\"x_LEVX.csv\",index_col=0)\n",
        "x_data=x_data.iloc[:,0:9]\n",
        "y_data=y_data[y_data>0]# delete station errors\n",
        "result = x_data.join(y_data, how='outer').dropna()\n",
        "x_data=result.iloc[:,0:9]\n",
        "y_data=result.iloc[:,9:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KTTTJpD2kPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NE=y_data[(y_data[\"value\"]>22.5) & (y_data[\"value\"]<67.5)]\n",
        "NE[\"label\"]=\"NE\"\n",
        "E=y_data[(y_data[\"value\"]>67.5) & (y_data[\"value\"]<112.5)]\n",
        "E[\"label\"]=\"E\"\n",
        "SE=y_data[(y_data[\"value\"]>112.5) & (y_data[\"value\"]<157.5)]\n",
        "SE[\"label\"]=\"SE\"\n",
        "S=y_data[(y_data[\"value\"]>157.5) & (y_data[\"value\"]<202.5)]\n",
        "S[\"label\"]=\"S\"\n",
        "SW=y_data[(y_data[\"value\"]>202.5) & (y_data[\"value\"]<247.5)]\n",
        "SW[\"label\"]=\"SW\"\n",
        "W=y_data[(y_data[\"value\"]>247.5) & (y_data[\"value\"]<292.5)]\n",
        "W[\"label\"]=\"W\"\n",
        "NW=y_data[(y_data[\"value\"]>292.5) & (y_data[\"value\"]<337.5)]\n",
        "NW[\"label\"]=\"NW\"\n",
        "N=y_data[(y_data[\"value\"]>337.5) | (y_data[\"value\"]<22.5)]\n",
        "N[\"label\"]=\"N\"\n",
        "winds=[NE,N,E,SE,S,SW,W,NW]\n",
        "y_data=pd.concat(winds)\n",
        "y_data=y_data.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWUwCiVPMAD0",
        "colab_type": "text"
      },
      "source": [
        "**Dummy **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07jqWkd6MJMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = DummyClassifier(strategy=\"most_frequent\").fit(x_train, y_train).predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDN28rwJt0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "619b8ba1-1103-43aa-f131-6fa9da120113"
      },
      "source": [
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    E  N  NE  NW    S  SE  SW  W\n",
            "E   0  0   0   0   44   0   0  0\n",
            "N   0  0   0   0  329   0   0  0\n",
            "NE  0  0   0   0  211   0   0  0\n",
            "NW  0  0   0   0   83   0   0  0\n",
            "S   0  0   0   0  509   0   0  0\n",
            "SE  0  0   0   0    6   0   0  0\n",
            "SW  0  0   0   0  423   0   0  0\n",
            "W   0  0   0   0  407   0   0  0\n",
            "****************\n",
            "Accuracy= 25.30% // Model Accuracy=45%\n",
            "Average precision = 3.16% // Model precision=28%\n",
            "Average recall = 12.50% // Model recall=28%\n",
            "Precision weighted= 6.40% //Model weighted=56%\n",
            "Recall weighted = 25.30% //Model weighted=53%\n",
            "****************\n",
            "       Precision  Recall        F1\n",
            "W_DIR                             \n",
            "E       0.000000     0.0  0.000000\n",
            "N       0.000000     0.0  0.000000\n",
            "NE      0.000000     0.0  0.000000\n",
            "NW      0.000000     0.0  0.000000\n",
            "S       0.252982     1.0  0.403808\n",
            "SE      0.000000     0.0  0.000000\n",
            "SW      0.000000     0.0  0.000000\n",
            "W       0.000000     0.0  0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9wywTaw7p9a",
        "colab_type": "text"
      },
      "source": [
        "**Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f22acda1-5537-46fb-fc98-593ecdddd2ed",
        "id": "okciK01rf1o-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "clas = [RandomForestClassifier(n_estimators= 200, max_depth= 100, bootstrap= True),\n",
        "       ExtraTreesClassifier(),AdaBoostClassifier(),GaussianNB()]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    E    N  NE  NW    S  SE   SW    W\n",
            "E   3    5  12   1    5   1    8    9\n",
            "N   1  213  39  12    7   0   21   36\n",
            "NE  5  107  54   2    6   0   14   23\n",
            "NW  1   25   4  11    5   0    3   34\n",
            "S   2   15   5   1  340   0  109   37\n",
            "SE  2    1   0   1    1   0    1    0\n",
            "SW  2   22   4   2  120   1  231   41\n",
            "W   4   37   6  13   23   0   47  277\n",
            "****************\n",
            "Accuracy= 56.11% // Model Accuracy=45%\n",
            "Average precision = 39.39% // Model precision=28%\n",
            "Average recall = 37.48% // Model recall=28%\n",
            "Precision weighted= 54.56% //Model weighted=56%\n",
            "Recall weighted = 56.11% //Model weighted=53%\n",
            "****************\n",
            "       Precision    Recall        F1\n",
            "W_DIR                               \n",
            "E       0.150000  0.068182  0.093750\n",
            "N       0.501176  0.647416  0.564987\n",
            "NE      0.435484  0.255924  0.322388\n",
            "NW      0.255814  0.132530  0.174603\n",
            "S       0.670611  0.667976  0.669291\n",
            "SE      0.000000  0.000000  0.000000\n",
            "SW      0.532258  0.546099  0.539090\n",
            "W       0.606127  0.680590  0.641204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jdSebxdAXlG",
        "colab_type": "text"
      },
      "source": [
        "**Synthetic samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OYFqxjJ9YN6",
        "colab_type": "code",
        "outputId": "9e7d9ec2-6293-447e-c094-ed8850f14e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.4, random_state=27)\n",
        "print(\"Original train samples=\",x_train.shape[0])\n",
        "sm = SMOTE(random_state=27,)\n",
        "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
        "print(\"Synthetic train samples=\",x_train.shape[0])\n",
        "\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original train samples= 4023\n",
            "Synthetic train samples= 8304\n",
            "     E    N   NE  NW    S  SE   SW    W\n",
            "E   19    3   12   0    2  11    2    8\n",
            "N   17  209  104  43    3   1   24   38\n",
            "NE  27   92   94  21    2   5   14   24\n",
            "NW   3   28    7  38    2   2    4   40\n",
            "S   26    7    9  12  446  20  164   25\n",
            "SE   5    2    2   0    3   1    2    1\n",
            "SW  21   18   12  10  125  25  294   37\n",
            "W   19   28   20  61   23   6   58  302\n",
            "****************\n",
            "Accuracy= 52.29% // Model Accuracy=45%\n",
            "Average precision = 39.43% // Model precision=28%\n",
            "Average recall = 40.89% // Model recall=28%\n",
            "Precision weighted= 56.12% //Model weighted=56%\n",
            "Recall weighted = 52.29% //Model weighted=53%\n",
            "****************\n",
            "       Precision    Recall        F1\n",
            "W_DIR                               \n",
            "E       0.138686  0.333333  0.195876\n",
            "N       0.540052  0.476082  0.506053\n",
            "NE      0.361538  0.336918  0.348794\n",
            "NW      0.205405  0.306452  0.245955\n",
            "S       0.735974  0.629055  0.678327\n",
            "SE      0.014085  0.062500  0.022989\n",
            "SW      0.523132  0.542435  0.532609\n",
            "W       0.635789  0.584139  0.608871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QSvWknSi8On",
        "colab_type": "text"
      },
      "source": [
        "**K_ folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p513UJ20jB3I",
        "colab_type": "code",
        "outputId": "f5ab953a-622a-4de9-90ee-b542eda71b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 53.52% (+/- 6.12%)\n",
            "Recall: 35.13% (+/- 3.60%)\n",
            "Precision: 35.89% (+/- 4.30%)\n",
            "f1 : 34.55% (+/-4.42% )\n",
            "Recall weighted: 53.52% (+/- 6.12%)\n",
            "Precision weighted: 52.00% (+/- 4.08%)\n",
            "f1 weighted: 51.68% (+/-6.17% )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyZ5x5boU5Cm",
        "colab_type": "text"
      },
      "source": [
        "**Tuning RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMuQydYdVA4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "00bca2a2-fe2b-4805-e395-da6b6c760f6f"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.25,\n",
        "                                                    random_state=27)\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
        "                               n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(x_train, y_train)\n",
        "print(\"best parameters\",rf_random.best_params_)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.0min\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  9.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt5mfmH3XJVU",
        "colab_type": "text"
      },
      "source": [
        "**K folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foRDGCKYW9O4",
        "colab_type": "code",
        "outputId": "7622ec54-d923-4d9e-d801-f45a6eb271b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "clas=RandomForestClassifier(n_estimators= 1000, min_samples_split= 10, min_samples_leaf= 1, max_features= 'sqrt', max_depth= 30, bootstrap= True)\n",
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas, x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 54.03% (+/- 5.64%)\n",
            "Recall: 35.19% (+/- 2.99%)\n",
            "Precision: 36.33% (+/- 3.52%)\n",
            "f1 : 34.44% (+/-3.82% )\n",
            "Recall weighted: 54.03% (+/- 5.64%)\n",
            "Precision weighted: 52.45% (+/- 2.90%)\n",
            "f1 weighted: 51.90% (+/-5.69% )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}