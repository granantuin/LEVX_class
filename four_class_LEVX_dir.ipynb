{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "four_class_LEVX_dir.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/granantuin/LEVX_class/blob/master/four_class_LEVX_dir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2yjZo0iz3Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix,accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,cross_validate,GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G2SFv5B0XBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvkfiKL3nOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(y_test,y_pred):\n",
        "  index=[\"E\",\"N\",\"NE\",\"NW\",\"S\",\"SE\",\"SW\",\"W\"]\n",
        "  print(pd.DataFrame(confusion_matrix(y_test, y_pred), index=index, columns=index))\n",
        "  print(\"****************\")\n",
        "  print(\"Accuracy=\",\"{:.2%}\".format(accuracy_score(y_test, y_pred)),\"// Model Accuracy=45%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average=None, )\n",
        "  df=pd.DataFrame({\"Precision\":results[0],\"Recall\":results[1],\"F1\":results[2],\"W_DIR\":index})\n",
        "  df=df.set_index(\"W_DIR\")\n",
        "  print(\"Average precision =\",\"{:.2%}\".format(df[\"Precision\"].mean()),\"// Model precision=28%\")\n",
        "  print(\"Average recall =\",\"{:.2%}\".format(df[\"Recall\"].mean()),\"// Model recall=28%\")\n",
        "  results= precision_recall_fscore_support(y_test, y_pred, average='weighted', )\n",
        "  print(\"Precision weighted=\",\"{:.2%}\".format(results[0]),\"//Model weighted=56%\")\n",
        "  print(\"Recall weighted =\",\"{:.2%}\".format(results[1]),\"//Model weighted=53%\")\n",
        "  print(\"****************\")\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHfznTP1-Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_4km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_4km_h24toh48_dir/\"\n",
        "drive_1km=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Coron_Mars_H24to48_dir/\"\n",
        "drive_metar=\"/content/drive/My Drive/Colab Notebooks/model_vs_data/Metar_2018/\"\n",
        "dr=[drive_4km,drive_1km,drive_metar]\n",
        "y_data=pd.read_excel(dr[2]+\"y_LEVX_dir.xlsx\",index_col=0)\n",
        "x_data=pd.read_csv(dr[2]+\"x_LEVX.csv\",index_col=0)\n",
        "x_data=x_data.iloc[:,0:9]\n",
        "y_data=y_data[y_data>0]# delete station errors\n",
        "result = x_data.join(y_data, how='outer').dropna()\n",
        "x_data=result.iloc[:,0:9]\n",
        "y_data=result.iloc[:,9:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2if4pGhGSLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KTTTJpD2kPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NE=y_data[(y_data[\"value\"]>22.5) & (y_data[\"value\"]<67.5)]\n",
        "NE[\"label\"]=\"NE\"\n",
        "E=y_data[(y_data[\"value\"]>67.5) & (y_data[\"value\"]<112.5)]\n",
        "E[\"label\"]=\"E\"\n",
        "SE=y_data[(y_data[\"value\"]>112.5) & (y_data[\"value\"]<157.5)]\n",
        "SE[\"label\"]=\"SE\"\n",
        "S=y_data[(y_data[\"value\"]>157.5) & (y_data[\"value\"]<202.5)]\n",
        "S[\"label\"]=\"S\"\n",
        "SW=y_data[(y_data[\"value\"]>202.5) & (y_data[\"value\"]<247.5)]\n",
        "SW[\"label\"]=\"SW\"\n",
        "W=y_data[(y_data[\"value\"]>247.5) & (y_data[\"value\"]<292.5)]\n",
        "W[\"label\"]=\"W\"\n",
        "NW=y_data[(y_data[\"value\"]>292.5) & (y_data[\"value\"]<337.5)]\n",
        "NW[\"label\"]=\"NW\"\n",
        "N=y_data[(y_data[\"value\"]>337.5) | (y_data[\"value\"]<22.5)]\n",
        "N[\"label\"]=\"N\"\n",
        "winds=[NE,N,E,SE,S,SW,W,NW]\n",
        "y_data=pd.concat(winds)\n",
        "y_data=y_data.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWUwCiVPMAD0",
        "colab_type": "text"
      },
      "source": [
        "**Dummy **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07jqWkd6MJMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = DummyClassifier(strategy=\"most_frequent\").fit(x_train, y_train).predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDN28rwJt0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "9be5a91e-48ff-4671-ff63-646d72c766dd"
      },
      "source": [
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    E  N  NE  NW    S  SE  SW  W\n",
            "E   0  0   0   0   44   0   0  0\n",
            "N   0  0   0   0  329   0   0  0\n",
            "NE  0  0   0   0  211   0   0  0\n",
            "NW  0  0   0   0   83   0   0  0\n",
            "S   0  0   0   0  509   0   0  0\n",
            "SE  0  0   0   0    6   0   0  0\n",
            "SW  0  0   0   0  423   0   0  0\n",
            "W   0  0   0   0  407   0   0  0\n",
            "****************\n",
            "Accuracy= 25.30% // Model Accuracy=45%\n",
            "Average precision = 3.16% // Model precision=28%\n",
            "Average recall = 12.50% // Model recall=28%\n",
            "Precision weighted= 6.40% //Model weighted=56%\n",
            "Recall weighted = 25.30% //Model weighted=53%\n",
            "****************\n",
            "       Precision  Recall        F1\n",
            "W_DIR                             \n",
            "E       0.000000     0.0  0.000000\n",
            "N       0.000000     0.0  0.000000\n",
            "NE      0.000000     0.0  0.000000\n",
            "NW      0.000000     0.0  0.000000\n",
            "S       0.252982     1.0  0.403808\n",
            "SE      0.000000     0.0  0.000000\n",
            "SW      0.000000     0.0  0.000000\n",
            "W       0.000000     0.0  0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9wywTaw7p9a",
        "colab_type": "text"
      },
      "source": [
        "**Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db30656f-1a53-48f7-b38e-073846d42b05",
        "id": "okciK01rf1o-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "clas = [RandomForestClassifier(n_estimators= 200, max_depth= 100, bootstrap= True),\n",
        "       ExtraTreesClassifier(),AdaBoostClassifier(),GaussianNB()]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data[\"label\"], test_size=0.3, random_state=5)\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    E    N  NE  NW    S  SE   SW    W\n",
            "E   3    6  12   1    8   1    4    9\n",
            "N   1  209  44  13    6   0   22   34\n",
            "NE  4  107  56   3    5   0   12   24\n",
            "NW  0   25   5  13    4   0    5   31\n",
            "S   3   15   4   0  338   0  114   35\n",
            "SE  2    1   0   0    2   0    0    1\n",
            "SW  3   20   7   4  123   0  223   43\n",
            "W   1   40   7  12   23   0   52  272\n",
            "****************\n",
            "Accuracy= 55.37% // Model Accuracy=45%\n",
            "Average precision = 39.43% // Model precision=28%\n",
            "Average recall = 37.31% // Model recall=28%\n",
            "Precision weighted= 53.89% //Model weighted=56%\n",
            "Recall weighted = 55.37% //Model weighted=53%\n",
            "****************\n",
            "       Precision    Recall        F1\n",
            "W_DIR                               \n",
            "E       0.176471  0.068182  0.098361\n",
            "N       0.494090  0.635258  0.555851\n",
            "NE      0.414815  0.265403  0.323699\n",
            "NW      0.282609  0.156627  0.201550\n",
            "S       0.664047  0.664047  0.664047\n",
            "SE      0.000000  0.000000  0.000000\n",
            "SW      0.516204  0.527187  0.521637\n",
            "W       0.605791  0.668305  0.635514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jdSebxdAXlG",
        "colab_type": "text"
      },
      "source": [
        "**Synthetic samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OYFqxjJ9YN6",
        "colab_type": "code",
        "outputId": "cd95423e-fd2a-41a5-a150-2ad545c61fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.4, random_state=27)\n",
        "print(\"Original train samples=\",x_train.shape[0])\n",
        "sm = SMOTE(random_state=27,)\n",
        "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
        "print(\"Synthetic train samples=\",x_train.shape[0])\n",
        "\n",
        "y_pred = clas[0].fit(x_train, y_train).predict(x_test)\n",
        "evaluate(y_test,y_pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original train samples= 4023\n",
            "Synthetic train samples= 8304\n",
            "     E    N   NE  NW    S  SE   SW    W\n",
            "E   21    3   13   0    2   9    3    6\n",
            "N   17  216  102  41    3   1   22   37\n",
            "NE  25   88   99  21    3   4   13   26\n",
            "NW   5   29    6  39    2   2    4   37\n",
            "S   29    8   10   9  441  20  166   26\n",
            "SE   5    2    2   0    3   1    2    1\n",
            "SW  23   19   12  10  123  20  296   39\n",
            "W   20   29   21  55   23   8   57  304\n",
            "****************\n",
            "Accuracy= 52.81% // Model Accuracy=45%\n",
            "Average precision = 40.05% // Model precision=28%\n",
            "Average recall = 41.86% // Model recall=28%\n",
            "Precision weighted= 56.55% //Model weighted=56%\n",
            "Recall weighted = 52.81% //Model weighted=53%\n",
            "****************\n",
            "       Precision    Recall        F1\n",
            "W_DIR                               \n",
            "E       0.144828  0.368421  0.207921\n",
            "N       0.548223  0.492027  0.518607\n",
            "NE      0.373585  0.354839  0.363971\n",
            "NW      0.222857  0.314516  0.260870\n",
            "S       0.735000  0.622003  0.673797\n",
            "SE      0.015385  0.062500  0.024691\n",
            "SW      0.525755  0.546125  0.535747\n",
            "W       0.638655  0.588008  0.612286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QSvWknSi8On",
        "colab_type": "text"
      },
      "source": [
        "**K_ folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p513UJ20jB3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas[0], x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyZ5x5boU5Cm",
        "colab_type": "text"
      },
      "source": [
        "**Tuning RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMuQydYdVA4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data[\"label\"], test_size=0.25,\n",
        "                                                    random_state=27)\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
        "                               n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(x_train, y_train)\n",
        "print(\"best parameters\",rf_random.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt5mfmH3XJVU",
        "colab_type": "text"
      },
      "source": [
        "**K folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foRDGCKYW9O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clas=RandomForestClassifier(n_estimators= 200, min_samples_split= 10, min_samples_leaf= 2, max_features= 'sqrt', max_depth= 50, bootstrap= True)\n",
        "scoring = ['precision_macro', 'recall_macro','f1_macro',\"accuracy\",\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"]\n",
        "scores = cross_validate(clas, x_data, y_data[\"label\"], scoring=scoring,\n",
        "                        cv=5, return_train_score=False)\n",
        "print(\"Accuracy: {:.2%} (+/- {:.2%})\" .format (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
        "print(\"Recall: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_macro\"].mean(), scores[\"test_recall_macro\"].std() * 2))\n",
        "print(\"Precision: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_macro\"].mean(), scores[\"test_precision_macro\"].std() * 2))\n",
        "print(\"f1 : {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
        "print(\"Recall weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_recall_weighted\"].mean(), scores[\"test_recall_weighted\"].std() * 2))\n",
        "print(\"Precision weighted: {:.2%} (+/- {:.2%})\" .format (scores[\"test_precision_weighted\"].mean(), scores[\"test_precision_weighted\"].std() * 2))\n",
        "print(\"f1 weighted: {:.2%} (+/-{:.2%} )\".format (scores[\"test_f1_weighted\"].mean(), scores[\"test_f1_weighted\"].std() * 2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}